import requests
import json
import time
import random

class Torob:
    def __init__(self):
        self.base_url = "https://api.torob.com/v4"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'fa-IR,fa;q=0.9,en;q=0.8',
            'Referer': 'https://torob.com/',
        }
    
    def search(self, query, page=0):
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ØªØ±Ø¨ Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø±ÙˆØ´"""
        print(f"ğŸ” Torob API: Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ '{query}'")
        
        # Ø±ÙˆØ´ 1: API Ø§ØµÙ„ÛŒ
        result = self._try_main_api(query, page)
        if result and result.get('results'):
            print(f"âœ… API Ø§ØµÙ„ÛŒ Ù…ÙˆÙÙ‚: {len(result['results'])} Ù…Ø­ØµÙˆÙ„")
            return result
        
        # Ø±ÙˆØ´ 2: API Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
        result = self._try_alternative_api(query, page)
        if result and result.get('results'):
            print(f"âœ… API Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…ÙˆÙÙ‚: {len(result['results'])} Ù…Ø­ØµÙˆÙ„")
            return result
        
        # Ø±ÙˆØ´ 3: ÙˆØ¨ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯
        result = self._try_web_scraping(query)
        if result and result.get('results'):
            print(f"âœ… ÙˆØ¨ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ù…ÙˆÙÙ‚: {len(result['results'])} Ù…Ø­ØµÙˆÙ„")
            return result
        
        # Ø±ÙˆØ´ 4: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
        print("âš ï¸ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ")
        return self._generate_mock_data(query)
    
    def _try_main_api(self, query, page):
        """ØªÙ„Ø§Ø´ Ø¨Ø§ API Ø§ØµÙ„ÛŒ"""
        try:
            url = f"{self.base_url}/base-search/"
            params = {
                'q': query,
                'page': page,
                'size': 24
            }
            
            print(f"ğŸ“¡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡: {url}")
            response = requests.get(url, params=params, headers=self.headers, timeout=15)
            print(f"ğŸ“Š Status Code: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f"ğŸ“¦ Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {type(data)}")
                return data
            else:
                print(f"âŒ Ø®Ø·Ø§ÛŒ HTTP: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± API Ø§ØµÙ„ÛŒ: {e}")
            return None
    
    def _try_alternative_api(self, query, page):
        """ØªÙ„Ø§Ø´ Ø¨Ø§ API Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†"""
        try:
            # API Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† ØªØ±Ø¨
            url = "https://api.torob.com/v4/product-search/"
            params = {
                'query': query,
                'page': page
            }
            
            response = requests.get(url, params=params, headers=self.headers, timeout=15)
            
            if response.status_code == 200:
                return response.json()
            return None
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± API Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†: {e}")
            return None
    
    def _try_web_scraping(self, query):
        """ÙˆØ¨ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ø§Ø² ØªØ±Ø¨"""
        try:
            import urllib.parse
            from bs4 import BeautifulSoup
            import re
            
            encoded_query = urllib.parse.quote(query)
            url = f"https://torob.com/search/?query={encoded_query}"
            
            headers = {
                'User-Agent': self.headers['User-Agent'],
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'fa-IR,fa;q=0.9,en;q=0.8',
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                results = []
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± HTML
                product_elements = soup.find_all(['div', 'article'], class_=re.compile(r'product|item'))
                
                for i, element in enumerate(product_elements[:10]):
                    try:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù…
                        title_elem = element.find(['h1', 'h2', 'h3', 'h4', 'a'], string=True)
                        title = title_elem.get_text().strip() if title_elem else f"{query} - Ù…Ø­ØµÙˆÙ„ {i+1}"
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª
                        price_elem = element.find(string=re.compile(r'[\d,]+.*ØªÙˆÙ…Ø§Ù†|[\d,]+.*Ø±ÛŒØ§Ù„'))
                        price = None
                        
                        if price_elem:
                            price_text = price_elem.strip()
                            numbers = re.findall(r'[\d,]+', price_text.replace('Ù¬', ','))
                            if numbers:
                                price = int(numbers[0].replace(',', ''))
                                if 'Ø±ÛŒØ§Ù„' in price_text:
                                    price = price // 10
                        
                        if price and price > 1000:
                            results.append({
                                'name1': title,
                                'price': price,
                                'prk': f"scraped-{i}",
                                'image_url': None,
                                'shops': [{'name': 'ØªØ±Ø¨', 'price': price}]
                            })
                    except:
                        continue
                
                return {'results': results} if results else None
            
            return None
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙˆØ¨ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯: {e}")
            return None
    
    def _generate_mock_data(self, query):
        """ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡"""
        results = []
        base_price = random.randint(100000, 2000000)
        
        for i in range(5):
            variation = random.randint(-50000, 100000)
            price = base_price + variation
            
            results.append({
                'name1': f"{query} - Ù…Ø¯Ù„ {i+1}",
                'price': price,
                'prk': f"mock-{i}",
                'image_url': None,
                'shops': [
                    {
                        'name': f'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {i+1}',
                        'price': price + random.randint(-10000, 10000)
                    }
                ]
            })
        
        return {'results': results}
    
    def details(self, prk, search_id=None):
        try:
            url = f"{self.base_url}/product-page/"
            params = {'prk': prk}
            if search_id:
                params['search_id'] = search_id
            
            response = requests.get(url, params=params, headers=self.headers, timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                return {}
        except Exception as e:
            print(f"Error in Torob details: {e}")
            return {}